{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CBF4srwOW3Mf"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c349a3320e34e309354fab7fd794c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c65bdbdfaa747d5a39b548f362caaed",
              "IPY_MODEL_a8760a12452d4594a24397e6de3db562",
              "IPY_MODEL_8d34b30030fa4d70bfdc34f02ca06052"
            ],
            "layout": "IPY_MODEL_70331f2cfe54499b8c28f3225a31a120"
          }
        },
        "5c65bdbdfaa747d5a39b548f362caaed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ea0843cc514f44907d93f4c4edc5f7",
            "placeholder": "​",
            "style": "IPY_MODEL_b9f76d17928e45f7b9a626d74323e6cc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a8760a12452d4594a24397e6de3db562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f15ea9fbe3434ed58ca6a58fca6b65fb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25e8d33e239d462ba74eef9849768724",
            "value": 2
          }
        },
        "8d34b30030fa4d70bfdc34f02ca06052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ff1ef60dfc4951a4e38c2e130dd65b",
            "placeholder": "​",
            "style": "IPY_MODEL_ef4a2c054c444d71b100aeffb4519fe9",
            "value": " 2/2 [00:46&lt;00:00, 21.95s/it]"
          }
        },
        "70331f2cfe54499b8c28f3225a31a120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ea0843cc514f44907d93f4c4edc5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f76d17928e45f7b9a626d74323e6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f15ea9fbe3434ed58ca6a58fca6b65fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e8d33e239d462ba74eef9849768724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ff1ef60dfc4951a4e38c2e130dd65b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef4a2c054c444d71b100aeffb4519fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run with HF"
      ],
      "metadata": {
        "id": "kxDS0KfDb9wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful digital assistant. Please provide safe, ethical and accurate information to the user.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you provide ways to eat combinations of bananas and dragonfruits?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Sure! Here are some ways to eat bananas and dragonfruits together: 1. Banana and dragonfruit smoothie: Blend bananas and dragonfruits together with some milk and honey. 2. Banana and dragonfruit salad: Mix sliced bananas and dragonfruits together with some lemon juice and honey.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What about solving an 2x + 3 = 7 equation?\"},\n",
        "]\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.0,\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "\n",
        "output = pipe(messages, **generation_args)\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "4c349a3320e34e309354fab7fd794c61",
            "5c65bdbdfaa747d5a39b548f362caaed",
            "a8760a12452d4594a24397e6de3db562",
            "8d34b30030fa4d70bfdc34f02ca06052",
            "70331f2cfe54499b8c28f3225a31a120",
            "f8ea0843cc514f44907d93f4c4edc5f7",
            "b9f76d17928e45f7b9a626d74323e6cc",
            "f15ea9fbe3434ed58ca6a58fca6b65fb",
            "25e8d33e239d462ba74eef9849768724",
            "f3ff1ef60dfc4951a4e38c2e130dd65b",
            "ef4a2c054c444d71b100aeffb4519fe9"
          ]
        },
        "id": "Is973o7scBQB",
        "outputId": "a67f12e6-01bf-45e6-db43-87bbfcd93317"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.b043e05a86cfc77f8d53eb0edf6a33e39afbcb5e.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.b043e05a86cfc77f8d53eb0edf6a33e39afbcb5e.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c349a3320e34e309354fab7fd794c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.b043e05a86cfc77f8d53eb0edf6a33e39afbcb5e.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To solve the equation 2x + 3 = 7, follow these steps:\n",
            "\n",
            "1. Subtract 3 from both sides of the equation to isolate the term with the variable (x):\n",
            "   2x + 3 - 3 = 7 - 3\n",
            "   2x = 4\n",
            "\n",
            "2. Divide both sides of the equation by 2 to solve for x:\n",
            "   2x / 2 = 4 / 2\n",
            "   x = 2\n",
            "\n",
            "So, the solution to the equation 2x + 3 = 7 is x = 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSr4tk7QhbQI",
        "outputId": "8b8aa7c9-7112-48db-96eb-c3aba73a150a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['generated_text'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with llama_cpp"
      ],
      "metadata": {
        "id": "s8FkZxh9TAj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update;\n",
        "!wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64 -O cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-10-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get -y install gcc-7 g++-7\n",
        "!apt-get -y install cuda\n",
        "\n",
        "!export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}"
      ],
      "metadata": {
        "id": "ktHOPsbkX8Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8TX7T8zTHbi",
        "outputId": "15d38f24-fb2a-4c42-e318-d145a86aec15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.64)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "nLrpDJf6TEHh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "  model_path=\"./Phi-3-mini-4k-instruct-q4.gguf\",  # path to GGUF file\n",
        "  n_ctx=4096,  # The max sequence length to use - note that longer sequence lengths require much more resources\n",
        "  n_threads=8, # The number of CPU threads to use, tailor to your system and the resulting performance\n",
        "  n_gpu_layers=35, # The number of layers to offload to GPU, if you have GPU acceleration available. Set to 0 if no GPU acceleration is available on your system.\n",
        ")"
      ],
      "metadata": {
        "id": "fjLe8mQ1T_9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"How to explain Internet to a medieval knight?\""
      ],
      "metadata": {
        "id": "o8kMrNjsUB--"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple inference example\n",
        "output = llm(\n",
        "  f\"<|user|>\\n{prompt}<|end|>\\n<|assistant|>\",\n",
        "  max_tokens=256,  # Generate up to 256 tokens\n",
        "  stop=[\"<|end|>\"],\n",
        "  echo=True,  # Whether to echo the prompt\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG3bA2qZUDXh",
        "outputId": "caefcec9-cf0b-4cb0-afa6-2b9d53f0f934"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     967.51 ms\n",
            "llama_print_timings:      sample time =     165.30 ms /   256 runs   (    0.65 ms per token,  1548.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     967.20 ms /    16 tokens (   60.45 ms per token,    16.54 tokens per second)\n",
            "llama_print_timings:        eval time =   38602.00 ms /   255 runs   (  151.38 ms per token,     6.61 tokens per second)\n",
            "llama_print_timings:       total time =   40738.45 ms /   271 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_U4YRwyUEvj",
        "outputId": "07b3a740-acff-4930-ce8b-31cedbac6a89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "How to explain Internet to a medieval knight?<|end|>\n",
            "<|assistant|> To explain the concept of the \"Internet\" to a medieval knight, we must simplify and draw parallels with familiar concepts:\n",
            "\n",
            "Imagine, noble knight, that you possess an invisible network connecting all people across vast lands. This magical web allows messengers (much like your own mounted couriers) to carry information at unthinkable speeds, as if by some arcane enchantment. Instead of relying solely on physical letters or word-of-mouth, this mystical realm enables people from distant lands to share knowledge and news instantaneously through a series of interconnected channels – much like a vast network of roads crisscrossing the kingdoms in your time.\n",
            "\n",
            "The \"Internet\" is an extraordinary library where every book ever written can be found at one's fingertips, accessible from anywhere within this web-like system. In essence, it connects distant lands and their inhabitants through a shared pool of information, enhancing communication and understanding among all peoples across the globe.\n",
            "\n",
            "However, keep in mind that these technological advances are born from human ingenuity rather than sorcery or mysticism. The power lies within our own ability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run with gguf"
      ],
      "metadata": {
        "id": "CBF4srwOW3Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7S9UefgW6um",
        "outputId": "363194dd-d1ef-49bc-96e9-5391af2be4fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.64)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cpp import Llama"
      ],
      "metadata": {
        "id": "CRNOUCWjXYUv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the location of to the GGUF model that you've download from HuggingFace here\n",
        "model_path = \"/content/drive/MyDrive/LLAMA/llama-cpp/Phi-3-mini-4k-instruct-q4.gguf\""
      ],
      "metadata": {
        "id": "AvQBeXRQXHKC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULkhKg_2XNvf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}